{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "za-2OB0CTRk9"
   },
   "source": [
    "# Tensores en pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDVC99tdTRk_"
   },
   "source": [
    "El framework **torch** está diseñada para que todo sea muy similar con el manejo de arrays multi-dimensionalidad de **numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1IWuvXHkTRlG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyRZI9diTRlH"
   },
   "source": [
    "## Creación de tensores\n",
    "\n",
    "Para crear un tensor se puede crear una instancia de\n",
    "- **numpy.ndarray** en **numpy**\n",
    "- **torch.Tensor** en **torch**\n",
    "\n",
    "Sin embargo, lo más indicado es utilizar funciones para crearlos de una manera más limpia, retornando los tipos de datos previamente mencionados:\n",
    "- **numpy.array** en **numpy**\n",
    "- **torch.tensor** en **torch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPN4P0zbTRlI"
   },
   "source": [
    "Definición de tensores de rango 0, 1, y 2. Se trata de matrices multidimensionales que se definen como numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8fSv2trTRlI",
    "outputId": "ad3d6ea5-9a17-45d2-fbd7-ab470b397a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 \n",
      " [12  3  6 14] \n",
      " [[ 5 78  2 34  0]\n",
      " [ 6 79  3 35  1]\n",
      " [ 7 80  4 36  2]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array(12)\n",
    "y = np.array([12,3,6,14])\n",
    "z = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "print(x, '\\n', y, '\\n', z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFg4Ay9HTRlJ",
    "outputId": "442a1930-5047-4408-e1f6-7e5d173cd29d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12) \n",
      " tensor([12,  3,  6, 14]) \n",
      " tensor([[ 5, 78,  2, 34,  0],\n",
      "        [ 6, 79,  3, 35,  1],\n",
      "        [ 7, 80,  4, 36,  2]])\n"
     ]
    }
   ],
   "source": [
    "x_t = torch.tensor(12)\n",
    "y_t = torch.tensor([12,3,6,14])\n",
    "z_t = torch.tensor([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "print(x_t, '\\n', y_t, '\\n', z_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80taEJYzTRlJ"
   },
   "source": [
    "Obtener el dimensionamiento (el número de ejes). Los escalares tienen 0 dimensiones, por convención."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrLRuhSLTRlK",
    "outputId": "80ebd372-7e01-46c4-9fa4-87f35b107198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2\n"
     ]
    }
   ],
   "source": [
    "print(x.ndim, y.ndim, z.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P36hJ2VRTRlK",
    "outputId": "a101fd3c-a51f-4d6a-cddc-7e536823ff25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2\n"
     ]
    }
   ],
   "source": [
    "print(x_t.ndim, y_t.ndim, z_t.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJ5nTnO9TRlK"
   },
   "source": [
    "Obtener la forma de los tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dstCpRnTRlL",
    "outputId": "936595d1-3f11-4a68-f090-4e1c3fcd3bd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "() (4,) (3, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape, z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0VwcRjOTRlL",
    "outputId": "aa7c7e2a-5f1a-4cb4-b2b3-396763d8825e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) torch.Size([4]) torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "print(x_t.shape, y_t.shape, z_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f6FDFdETRlL"
   },
   "source": [
    "Se puede dar el caso de que se abuse utilizando el término \"dimensiones\" para referirse al \"rango\" o al número de \"ejes\" de un tensor.\n",
    "\n",
    "El primer tensor es un escalar. el segundo es un array con un eje de 4 dimensiones. El tercero es un tensor de rango 2, con 3 dimensiones en el primer eje y 5 dimensiones en el segundo eje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPipuL3jTRlM"
   },
   "source": [
    "Podemos convertir de tensores de torch a arrays multidimensionales de numpy con el método **.numpy()** de la clase **torch.Tensor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4Fcw-h-TRlM",
    "outputId": "558850bc-5225-46d0-8d76-b45307e951a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 78,  2, 34,  0],\n",
       "       [ 6, 79,  3, 35,  1],\n",
       "       [ 7, 80,  4, 36,  2]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_t.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SwTD9tsTRlM"
   },
   "source": [
    "Para tensores de rango 0 (escalares), se puede aplicar el método **item()** que retorna el valor correspondiente, resultado diferente al de llamar **numpy()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AIPQcrcYTRlM",
    "outputId": "c17a35d9-679c-4403-9ea9-623fc5687ebb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12, dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMnw82nATRlN",
    "outputId": "d00c5244-9826-4047-e702-98e78e9deb97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKYOIvjSTRlN"
   },
   "source": [
    "Para crear un tensor con valores aleatorios, se utiliza la función **torch.rand()**, indicando la dimensionalidad del tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UM2J1HaZTRlN",
    "outputId": "4b248003-8bf6-45ed-c684-f83788cc5b14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9034, 0.0895, 0.5214, 0.5137, 0.4154],\n",
       "        [0.6004, 0.5867, 0.1891, 0.0662, 0.4810],\n",
       "        [0.9953, 0.2214, 0.4408, 0.8284, 0.8722]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.rand(3,5)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKl8vSjeTRlO"
   },
   "source": [
    "Se puede crear tensores con valores predeterminados con las funciones **torch.ones()**, **torch.zeros()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2kAMAipTRlO",
    "outputId": "b8ccdc20-c083-4097-9c5b-9c8755363947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "unos = torch.ones(5)\n",
    "print(unos)\n",
    "zeros = torch.zeros(3)\n",
    "print(zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede crear tensores \"vacíos\" con **torch.empty()**, para luego inicializarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.1950e-43, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8888e+31, 4.7414e+16,\n",
      "        6.3371e-10, 5.3483e+22, 2.5180e-12, 4.0967e-11])\n",
      "tensor([ 1.7327, -0.2745,  1.0904,  0.0665, -0.7550,  1.8800,  0.0812, -0.6130,\n",
      "        -0.2380,  0.6516])\n",
      "tensor(0.0064) tensor(0.9985)\n"
     ]
    }
   ],
   "source": [
    "vacio = torch.empty(5000)\n",
    "print(vacio[:10])\n",
    "torch.nn.init.normal_(vacio)\n",
    "print(vacio[:10])\n",
    "print(vacio.mean(), vacio.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9YV3_BDTRlO"
   },
   "source": [
    "Al crear tensores que representen parámetros que se quieren entrenar a partir de descenso de gradiente, se debe indicar que se requiere monitorear sus gradientes, con el argumento ```requires_grad=True```, ya que por defecto este argumento está seteado en ```False```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vp0vDuv3TRlO",
    "outputId": "aa845d35-b571-4b0b-ec38-cc824354679b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4262,  1.6204, -0.4838],\n",
      "        [ 1.0955, -0.4632, -1.1157],\n",
      "        [-0.0974, -0.1109, -0.6973],\n",
      "        [ 0.7594, -1.3064,  0.8943],\n",
      "        [ 0.7797,  1.0242, -0.6823]], requires_grad=True)\n",
      "tensor([ 0.5129, -0.2001,  0.9694], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "print(w)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHtFrO8iTRlP"
   },
   "source": [
    "## Tipo de datos de los tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1-10GShTRlP",
    "outputId": "687b1740-b2d2-4f92-cf33-e210acdaa4ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64 int64 int64 float64\n"
     ]
    }
   ],
   "source": [
    "w = np.array([4.3, 5.6])\n",
    "print(x.dtype, y.dtype, z.dtype, w.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYQSVxjPTRlP",
    "outputId": "cff30457-dafa-4f37-de04-3759fbca142f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.int64 torch.int64 torch.float32\n"
     ]
    }
   ],
   "source": [
    "w_t = torch.tensor([4.3, 5.6])\n",
    "print(x_t.dtype, y_t.dtype, z_t.dtype, w_t.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nlf4eBZdTRlP"
   },
   "source": [
    "No se tienen los mismos tipos por defecto (ver los floats), se puede hacer cambio de la representación de los elementos de los tensores en torch.\n",
    "De hecho, para redes neuronales, es mejor utilzar una representación menos precisa (float32), para optimizar el espacio en memoria RAM y velocidad de procesamiento.\n",
    "Se puede especificar explícitamente el tipo de un tensor en la función **tensor()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uljfq27ITRlP",
    "outputId": "a06a110f-f81c-41b8-834f-3d60aef4aad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1., 2.], dtype=torch.float64)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBUipPvNTRlQ"
   },
   "source": [
    "En **torch**, se puede también obtener versiones de tensores existentes con otros tipos, usando métodos como **double()** o **to()** (indicando el tipo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UuloEHQ8TRlQ",
    "outputId": "0d3d4f22-b7f9-446d-956c-f3bf4ad949e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.])\n",
      "tensor([1., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1., 2.]) # por defecto es igual a especificar dtype=torch.float32\n",
    "print(a)\n",
    "b = a.double()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VgyTwqmTRlQ",
    "outputId": "53094d44-1593-45c7-ad88-758797cdd793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "c = a.to(torch.float64)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lLDVnTxTRlQ"
   },
   "source": [
    "## Dimensionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtpcMZcvTRlQ"
   },
   "source": [
    "Al igual que la dimensionalidad de los arrays en numpy se puede modificar con la función **reshape()**, se puede cambiar la forma (dimensiones) de los tensores existentes con el método **view()**. \n",
    "Es necesario que las nuevas dimensiones sean compatibles con las dimensiones del tensor original, de lo contrario, ocurrirá un error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fV_gKF1wTRlR",
    "outputId": "f9b5d516-88aa-4657-9dc3-9ada63f3cef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.arange(1,25,2)\n",
    "print(f\"shape: {f.shape}\")\n",
    "f.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYJfdlQnTRlR",
    "outputId": "29693324-cee3-4556-dfa6-0bc0166e98fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  5,  7],\n",
       "       [ 9, 11, 13, 15],\n",
       "       [17, 19, 21, 23]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2 = f.view(3, 4)\n",
    "print(f\"shape: {f2.shape}\")\n",
    "f2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QymDoTaVTRlR",
    "outputId": "51d3b04e-3d62-44f7-83ff-fe6d80914fa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([6, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3],\n",
       "       [ 5,  7],\n",
       "       [ 9, 11],\n",
       "       [13, 15],\n",
       "       [17, 19],\n",
       "       [21, 23]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3 = f2.view(6, 2)\n",
    "print(f\"shape: {f3.shape}\")\n",
    "f3.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_hmizvxYTRlR",
    "outputId": "e59684c7-f41a-4de1-f3b9-edfd87964bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  5],\n",
       "       [ 7,  9, 11],\n",
       "       [13, 15, 17],\n",
       "       [19, 21, 23]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f4 = f3.view(4, 3)\n",
    "print(f\"shape: {f4.shape}\")\n",
    "f4.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-90UEwqTRlS"
   },
   "source": [
    "Con la función **torch.reshape()** se puede realizar la misma operación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgvsg58hTRlS",
    "outputId": "cf5eee97-9a1e-4864-809a-68f96ed4ada7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  5],\n",
       "       [ 7,  9, 11],\n",
       "       [13, 15, 17],\n",
       "       [19, 21, 23]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f4 = torch.reshape(f3, (4, 3))\n",
    "print(f\"shape: {f4.shape}\")\n",
    "f4.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NZJ3FqkTRlS"
   },
   "source": [
    "Se puede realizar la transposición de un tensor, indicando los dos rangos que se desean intercambiar, con el método **torch.transpose()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DTz_8hMmTRlT",
    "outputId": "c028bf51-e716-4607-df1a-4442a702b98b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 6])\n",
      "torch.Size([6, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "f5 = torch.rand(2,4,6)\n",
    "f6 = torch.transpose(f5, 0, 2)\n",
    "print(f5.shape)\n",
    "print(f6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTz_mC4MTRlT"
   },
   "source": [
    "Se utiliza el método **torch.squeeze()** para simplificar tensores con rangos de dimensionalidad 1, indicando el índice a tratar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVNg8qIGTRlT",
    "outputId": "e016ee97-89f1-4a8c-be9e-c150283eafe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28, 1])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "f7 = torch.rand(1, 28, 28, 1)\n",
    "print(f7.shape)\n",
    "f8 = torch.squeeze(f7, 3)\n",
    "print(f8.shape)\n",
    "f8 = torch.squeeze(f8, 0)\n",
    "print(f8.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZMk3QKsTRlU"
   },
   "source": [
    "Si se quiere dividir el primer rango de un tensor en varios tensores se pueden utilizar las funciones:\n",
    "- **torch.chunk()**, indicando el número de pedazos que se desean; el tamaño del vector original debe ser divisible por el número de pedazos, so pena de no obtener todos los pedazos deseados\n",
    "- **torch.split()**, indicando los tamaños de los pedazos que se desean en una lista; los tamaños deben sumar el tamaño del tensor original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qiJPJrKmTRlU",
    "outputId": "3d405959-9f0a-4339-e361-02dbaa854600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n",
      "(tensor([0.4166, 0.9691, 0.7767]), tensor([0.7785, 0.1937, 0.6786]), tensor([0.5722, 0.4367, 0.5366]), tensor([0.5106, 0.5720, 0.9122]))\n",
      "(tensor([0.4166, 0.9691, 0.7767]), tensor([0.7785, 0.1937, 0.6786]), tensor([0.5722, 0.4367, 0.5366]), tensor([0.5106, 0.5720, 0.9122]))\n",
      "(tensor([0.4166, 0.9691]), tensor([0.7767, 0.7785]), tensor([0.1937, 0.6786]), tensor([0.5722, 0.4367]), tensor([0.5366, 0.5106]), tensor([0.5720, 0.9122]))\n"
     ]
    }
   ],
   "source": [
    "f9 = torch.rand(12)\n",
    "print(f9.shape)\n",
    "tensor_list = torch.chunk(f9, 4)\n",
    "print(tensor_list)\n",
    "tensor_list = torch.chunk(f9, 5)\n",
    "print(tensor_list)\n",
    "tensor_list = torch.chunk(f9, 6)\n",
    "print(tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uDz194wTRlU",
    "outputId": "cad207d4-8d3c-4350-ac39-66e8dafc8fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.4166, 0.9691, 0.7767, 0.7785]), tensor([0.1937, 0.6786]), tensor([0.5722, 0.4367, 0.5366, 0.5106, 0.5720]), tensor([0.9122]))\n",
      "(tensor([0.4166, 0.9691, 0.7767, 0.7785]), tensor([0.1937, 0.6786, 0.5722]), tensor([0.4367, 0.5366, 0.5106]), tensor([0.5720, 0.9122]))\n"
     ]
    }
   ],
   "source": [
    "torch_list = torch.split(f9, (4,2,5,1))\n",
    "print(torch_list)\n",
    "torch_list = torch.split(f9, (4,3,3,2))\n",
    "print(torch_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usc-DZjTTRlU"
   },
   "source": [
    "Si lo que se desea es fusionar varios tensores, se pueden utilizar las siguientes funciones:\n",
    "- **torch.cat()**: se indican los tensores a fusionar en una lista, con el eje del rango a seguir, los demás ejes deben tener la misma dimensionalidad para que se puedan concatenar los tensores.\n",
    "- **torch.stack()**: se apilan los tensores siguiendo un eje; debe haber consistencia en los ejes diferentes a los de apilación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pEBQm6qTRlV",
    "outputId": "e4ad34ea-01ec-452c-eb64-78e5ce1239b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2, 5])\n",
      "torch.Size([3, 4, 5])\n",
      "torch.Size([3, 2, 10])\n"
     ]
    }
   ],
   "source": [
    "f10 = torch.rand(3, 2, 5)\n",
    "f11 = torch.rand(3, 2, 5)\n",
    "print(torch.cat([f10, f11], axis=0).shape)\n",
    "print(torch.cat([f10, f11], axis=1).shape)\n",
    "print(torch.cat([f10, f11], axis=2).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8_U699GcTRlV",
    "outputId": "b640c0a5-6145-49d5-f6fa-d5afe227dd74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor([[1., 1., 1.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "f12 = torch.ones(3)\n",
    "f13 = torch.zeros(3)\n",
    "print(f12)\n",
    "print(torch.stack([f12, f13], axis=0))\n",
    "print(torch.stack([f12, f13], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gomlDogpTRlV"
   },
   "source": [
    "## Operaciones sobre tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBE9a6PRTRlV"
   },
   "source": [
    "**Operaciones básicas** de sumas, restas, multiplicaciones y divisiones, realizadas elemento por elemento se hacen con el operador matemático correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ro1CaFbeTRlV",
    "outputId": "24ebb197-b0a6-48dc-8a66-fb73c7fd1769"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma: tensor([3, 4, 5, 6, 7, 8])\n",
      "Resta: tensor([-1,  0,  1,  2,  3,  4])\n",
      "Multiplicación: tensor([ 2,  4,  6,  8, 10, 12])\n",
      "División: tensor([0.5000, 1.0000, 1.5000, 2.0000, 2.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "b = torch.tensor([2, 2, 2, 2, 2, 2])\n",
    "print(f\"Suma: {a+b}\")\n",
    "print(f\"Resta: {a-b}\")\n",
    "print(f\"Multiplicación: {a*b}\")\n",
    "print(f\"División: {a/b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHvAIM4PTRlV"
   },
   "source": [
    "**Broadcasting**: combinar tensores de rangos diferentes de manera automática, suponiendo repetición de los valores a través de los rangos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6SP3iaYLTRlW",
    "outputId": "1025de63-1403-45ac-d5a3-2ff9e0c51af3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "tensor([4, 5, 6, 7, 8, 9])\n",
      "tensor([ 3,  6,  9, 12, 15, 18])\n",
      "tensor([ 3.,  6.,  9., 12., 15., 18.])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(a+3)\n",
    "print(a*3)\n",
    "print(a*3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gsb0gVRrTRlW",
    "outputId": "453dcb0c-7fa6-4a00-ce70-c97a82daa0fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "c: tensor([9, 8, 7])\n",
      "b+c: tensor([[10, 10, 10],\n",
      "        [13, 13, 13]])\n",
      "b+1: tensor([[2, 3, 4],\n",
      "        [5, 6, 7]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.tensor([[1,2,3], [4,5,6]])\n",
    "print(f\"b: {b}\")\n",
    "c = torch.tensor([9, 8, 7])\n",
    "print(f\"c: {c}\")\n",
    "print(f\"b+c: {b+c}\")\n",
    "print(f\"b+1: {b+1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BasQR8NaTRlW"
   },
   "source": [
    "**Producto punto** (producto interno):\n",
    "- **.dot()** en numpy, o el operador de multiplicación de matrices \"**@**\".\n",
    "- **.matmul()** o **.dot()** en **torch** (son equivalentes)\n",
    "- recientemente se incluyó el operador **@** en **torch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acirrgs0TRlW",
    "outputId": "a46c6e51-4436-4eac-b903-eceaf0d4ecd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12  3  6 14]\n",
      "385\n",
      "385\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(y.dot(y))\n",
    "print(y @ y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EFQe9RhtTRla",
    "outputId": "593840b6-b6db-4808-f70a-242c51fc66a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(385)\n",
      "tensor(385)\n",
      "tensor(385)\n"
     ]
    }
   ],
   "source": [
    "print(y_t.matmul(y_t))\n",
    "print(y_t.dot(y_t))\n",
    "print(y_t @ y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0xQG-PVTRla"
   },
   "source": [
    "En el contexto de las redes neuronales, durante la fase de feedforward, en cada capa $l$ (con su matriz de pesos $W$ y su vector de sesgos $b$) se realiza una **combinación lineal** para el batch de instancias $X$, obteniendo así el **net input** correspondiente:\n",
    "$z^{[l]} = W^{[l]}*x + b$. \n",
    "\n",
    "Supongamos que tenemos la capa $l$ tiene 5 neuronas, que está conectada a una capa anterior de 4 neuronas, y que tenemos un batch de 8 registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJKKR-dFTRla",
    "outputId": "8b692c88-cdeb-4fa7-f510-81c3f284c2a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: torch.Size([5, 4])\n",
      "X: torch.Size([4, 8])\n",
      "b: torch.Size([5, 1])\n",
      "Z: torch.Size([5, 8])\n",
      "Salidas de las 5 neuronas de la capa l, para las 8 instancias del batch\n",
      "tensor([[ 112,  118,  124,  130,  136,  142,  148,  154],\n",
      "        [ 305,  327,  349,  371,  393,  415,  437,  459],\n",
      "        [ 498,  536,  574,  612,  650,  688,  726,  764],\n",
      "        [ 691,  745,  799,  853,  907,  961, 1015, 1069],\n",
      "        [ 884,  954, 1024, 1094, 1164, 1234, 1304, 1374]])\n"
     ]
    }
   ],
   "source": [
    "n_l = 5\n",
    "n_l_1 = 4\n",
    "m = 8\n",
    "\n",
    "W = torch.arange(n_l * n_l_1).view(n_l, n_l_1)\n",
    "print(f\"W: {W.shape}\")\n",
    "\n",
    "X = torch.arange(n_l_1 * m).view(n_l_1, m)\n",
    "print(f\"X: {X.shape}\")\n",
    "\n",
    "b = torch.arange(n_l * 1).view(n_l, 1)\n",
    "print(f\"b: {b.shape}\")\n",
    "\n",
    "Z = W.matmul(X) + b\n",
    "print(f\"Z: {Z.shape}\")\n",
    "\n",
    "print(f\"Salidas de las {n_l} neuronas de la capa l, para las {m} instancias del batch\\n{Z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ott_5r8TRlb"
   },
   "source": [
    "# Diferenciación automática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkUzaTijTRlb"
   },
   "source": [
    "Para ilustrar como funciona la diferenciación automática, vamos a crear un modelo \"a pie\":\n",
    "- que tiene con 5 neuronas de entrada **x**, y 3 neuronas de salida binarias **y**.\n",
    "- lo que implica crear como parámetros un tensor de pesos **w** (5, 3), y un vector de sesgos **b** de 3 posiciones, que requieren tener seguimiento de gradientes, por lo que se especifica ```requires_grad=True```.\n",
    "- se calcula los net inputs **z** correspondientes\n",
    "- se utiliza una función de pérdida binary cross entropy con la función ```torch.nn.functional.binary_cross_entropy_with_logits()```, que no requiere aplicar una función softmax para calcular las probabilidades, sino que trabaja directamente con los logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Njs4XslCTRlb"
   },
   "outputs": [],
   "source": [
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtqlvP8VTRlb"
   },
   "source": [
    "Los gradientes indicados no se calculan hasta que no se dé una orden específica. Estos quedarán almacenados en el atributo ```grad``` de los tensores monitoreados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nO8E1mjdTRlb",
    "outputId": "7b9b8a01-5acb-4a3d-ba7e-f3dfcc52e7b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AflwgKkzTRlb"
   },
   "source": [
    "Con el método ```backward```, llamado sobre el tensor correspondiente, se realiza la propagación y cálculo de los gradientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4HvCLj-TRlb",
    "outputId": "a3b027b9-8ec1-4729-bada-6b8e8058ebd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[0.0098, 0.0094, 0.0431],\n",
      "        [0.0098, 0.0094, 0.0431],\n",
      "        [0.0098, 0.0094, 0.0431],\n",
      "        [0.0098, 0.0094, 0.0431],\n",
      "        [0.0098, 0.0094, 0.0431]])\n",
      "tensor([0.0098, 0.0094, 0.0431])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STVVe7NtTRlc"
   },
   "source": [
    "Por defecto, los gradientes solo se pueden calcular sobre un resultado una sola vez. Una vez se llama al método ```backward()```, pues los valores intermediarios monitoreados se liberan.\n",
    "Si se quiere llamar mas de una vez al método ```backward```, se debe especificar el argumento ```retain_graph=True```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "yfxkcowATRlc"
   },
   "outputs": [],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
    "loss.backward(retain_graph=True)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMKfQR-4TRlc"
   },
   "source": [
    "Solo necesitamos monitorear los gradientes durante el entrenamiento.\n",
    "Cuando tenemos un modelo en producción y solo requerimos hacer inferencia, para mejorar el performance del proceso, los gradientes se pueden deshabilitar creando un bloque ```no_grad()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5Bnd5T7TRlc",
    "outputId": "00b32548-3872-4a88-ad07-3371d9b0a186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJ_23SSJTRlc"
   },
   "source": [
    "También se puede desligar el monitoreo de un tensor con su método ```detach()```.\n",
    "En modelos con **transfer learning**, se pueden congelar los gradientes de ciertas capas de modelos transferidos utilizando este método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FlcDs_LWTRlc",
    "outputId": "0c8b5dc2-afc3-4c17-de56-79c5f071e0c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtguJJJ-TRld"
   },
   "source": [
    "# Paralelización con GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHzzojZsTRld"
   },
   "source": [
    "Por defecto el dispositivo de procesamiento y almacenamiento es la CPU.\n",
    "En caso de dispongamos de una GPU CUDA, y queramos utilizarla, necesitamos especificárselo a PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRk9YxPpTRld",
    "outputId": "76418ce3-ba1f-4d3c-e003-e5f39334a928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay GPU, toca correr todo en CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Utilizamos la primera GPU disponible\")\n",
    "    device='cuda:0'\n",
    "else:\n",
    "    print(\"No hay GPU, toca correr todo en CPU\")\n",
    "    device='cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ikVU9yXTRld"
   },
   "source": [
    "Al crear un tensor, especificamos el dispositivo (CPU o GPU) que vamos a utilizar para almacenarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ElF41zB7TRld",
    "outputId": "ab243ea7-3430-466b-84a1-dddbe68cd9c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1., 2., 3.], device=torch.device(device))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IddPgL8TRld"
   },
   "source": [
    "Comparemos el tiempo que toma el cálculo de una multiplicación de una matriz cuadrada por si misma. \n",
    "<font color=\"Red\">Esta sección solo tiene sentido en caso de disponer de una GPU.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aZlWBtb9Tzmd"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3vydzH4rTRle",
    "outputId": "df28e483-2b62-4886-8f3c-f6d4ca8be89c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 14.45068s\n",
      "GPU time: 1.66085s\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10000, 10000)\n",
    "\n",
    "## CPU version\n",
    "start_time = time.time()\n",
    "_ = torch.matmul(x, x)\n",
    "end_time = time.time()\n",
    "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
    "\n",
    "## GPU version\n",
    "x = x.to(device)\n",
    "# CUDA is asynchronous, so we need to use different timing functions\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "start.record()\n",
    "_ = torch.matmul(x, x)\n",
    "end.record()\n",
    "torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
    "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAiwVDjcTRle"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1-intro.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ca457c4d5855f91b63b4e3f4f9f155259cb120d23cbf731d35e7103ec65654d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
